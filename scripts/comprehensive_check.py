#!/usr/bin/env python3
"""
å…¨é¢æ£€æŸ¥ LDFA_SourcesAndSinks.txt çš„è´¨é‡å’Œå®Œæ•´æ€§
"""

import re
from pathlib import Path
from collections import defaultdict
from typing import Set, Tuple, List


def load_entries(file_path: Path) -> Tuple[Set[str], Set[str]]:
    """åŠ è½½æ‰€æœ‰ sources å’Œ sinks"""
    sources = set()
    sinks = set()

    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line or line.startswith('#'):
                continue
            if '_SOURCE_' in line:
                sources.add(line)
            elif '_SINK_' in line:
                sinks.add(line)

    return sources, sinks


def check_format_consistency(sources: Set[str], sinks: Set[str]) -> List[str]:
    """æ£€æŸ¥æ ¼å¼ä¸€è‡´æ€§é—®é¢˜"""
    issues = []

    all_entries = sources | sinks

    # æ£€æŸ¥1: æ˜¯å¦è¿˜æœ‰ Smali æ ¼å¼çš„ç±»å‹ç­¾å
    smali_pattern = re.compile(r'L[a-zA-Z/$]+;')
    for entry in all_entries:
        if smali_pattern.search(entry):
            issues.append(f"âŒ å‘ç° Smali æ ¼å¼: {entry[:80]}...")

    # æ£€æŸ¥2: æ˜¯å¦æœ‰ç©ºæ ¼ä¸ä¸€è‡´çš„é—®é¢˜ï¼ˆå‚æ•°ä¹‹é—´ï¼‰
    # æå–æ‰€æœ‰æ–¹æ³•ç­¾å
    method_sigs = defaultdict(list)
    for entry in all_entries:
        # æå–æ–¹æ³•ç­¾åéƒ¨åˆ†ï¼ˆåœ¨ -> ä¹‹å‰ï¼‰
        sig_part = entry.split('->')[0].strip()

        # æ ‡å‡†åŒ–ï¼šç§»é™¤å‚æ•°ä¹‹é—´çš„ç©ºæ ¼
        normalized = re.sub(r',\s+', ',', sig_part)

        # æå–æ–¹æ³•åå’Œå‚æ•°éƒ¨åˆ†ï¼ˆç”¨äºåˆ†ç»„ï¼‰
        match = re.match(r'([^:]+: [^(]+)\(([^)]*)\)', sig_part)
        if match:
            class_return = match.group(1)
            params = match.group(2)

            # æ ‡å‡†åŒ–å‚æ•°
            normalized_params = re.sub(r',\s+', ',', params)
            key = f"{class_return}({normalized_params})"

            method_sigs[key].append(entry)
        else:
            issues.append(f"âš ï¸  æ— æ³•è§£æçš„æ–¹æ³•ç­¾å: {entry[:80]}...")

    # æ£€æŸ¥3: æŸ¥æ‰¾å¯èƒ½çš„é‡å¤ï¼ˆå‚æ•°æ ¼å¼ä¸åŒï¼‰
    duplicates = []
    for key, entries in method_sigs.items():
        if len(entries) > 1:
            duplicates.append((key, entries))

    if duplicates:
        issues.append(f"\nğŸ” å‘ç° {len(duplicates)} ç»„å¯èƒ½çš„é‡å¤ï¼ˆå‚æ•°æ ¼å¼ä¸åŒï¼‰:")
        for key, entries in duplicates[:10]:  # åªæ˜¾ç¤ºå‰10ç»„
            issues.append(f"   æ–¹æ³•: {key}")
            for entry in entries:
                issues.append(f"     - {entry[:100]}")
        if len(duplicates) > 10:
            issues.append(f"   ... è¿˜æœ‰ {len(duplicates) - 10} ç»„")

    # æ£€æŸ¥4: æŸ¥æ‰¾æ„é€ å‡½æ•°ï¼ˆ<init>ï¼‰
    constructors = [e for e in all_entries if '<init>' in e]
    if constructors:
        issues.append(f"\nâœ“ æ„é€ å‡½æ•°: {len(constructors)} ä¸ª")
        for cons in constructors[:5]:
            issues.append(f"   - {cons[:100]}")
        if len(constructors) > 5:
            issues.append(f"   ... è¿˜æœ‰ {len(constructors) - 5} ä¸ª")

    return issues


def compare_with_sources(sources: Set[str], sinks: Set[str]) -> List[str]:
    """ä¸åŸå§‹æ–‡ä»¶å¯¹æ¯”ï¼Œæ£€æŸ¥è¦†ç›–ç‡"""
    issues = []

    base_dir = Path('/Users/zhangyiming/My_Documents/My_Code/LDFA-dataset/TaintBench')
    original_files = {
        'TB': 'TB_SourcesAndSinks.txt',
        'AD': 'AD_SourcesAndSinks.txt',
        'DB': 'DB_SourcesAndSinks.txt',
        'FD': 'FD_SourcesAndSinks.txt',
    }

    all_entries = sources | sinks

    # åˆ›å»ºæŸ¥æ‰¾ç´¢å¼•
    created_index = defaultdict(set)
    for entry in all_entries:
        # æå–ç±»åå’Œæ–¹æ³•å
        match = re.match(r'([^:]+):\s*(?:[^:]+:\s*)?(\w+)\s*\(', entry)
        if match:
            class_name = match.group(1)
            method_name = match.group(2)
            created_index[(class_name, method_name)].add(entry)

    # æ£€æŸ¥æ¯ä¸ªåŸå§‹æ–‡ä»¶
    for file_tag, file_name in original_files.items():
        file_path = base_dir / file_name
        if not file_path.exists():
            continue

        missing = []
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith('%') or line.startswith('#'):
                    continue

                # æå–æ–¹æ³•ä¿¡æ¯
                # Jimple æ ¼å¼
                match = re.match(r'<([^:>]+):\s*([^:]+)\s+(\w+)\s*\(', line)
                if match:
                    class_name = match.group(1)
                    method_name = match.group(3)
                else:
                    # ä¸å¸¦å°–æ‹¬å·çš„ Jimple æ ¼å¼
                    match = re.match(r'([^:>]+):\s*(?:[^:]+:\s*)?(\w+)\s*\(', line)
                    if match:
                        class_name = match.group(1)
                        method_name = match.group(2)
                    else:
                        # Smali æ ¼å¼
                        match = re.match(r'L([^;]+);\.([^:]+):\s*\(', line)
                        if match:
                            class_name = match.group(1).replace('/', '.')
                            method_name = match.group(2)
                        else:
                            continue

                key = (class_name, method_name)
                if key not in created_index:
                    missing.append(f"{class_name}.{method_name}")

        if missing:
            issues.append(f"\nâš ï¸  {file_tag} æ–‡ä»¶ä¸­æœ‰ {len(missing)} ä¸ªæ–¹æ³•å¯èƒ½åœ¨åˆå¹¶åˆ—è¡¨ä¸­ç¼ºå¤±:")
            for m in missing[:10]:
                issues.append(f"   - {m}")
            if len(missing) > 10:
                issues.append(f"   ... è¿˜æœ‰ {len(missing) - 10} ä¸ª")

    return issues


def check_specific_patterns(sources: Set[str], sinks: Set[str]) -> List[str]:
    """æ£€æŸ¥ç‰¹å®šçš„æ–¹æ³•å’Œç±»å‹"""
    issues = []

    all_entries = sources | sinks

    # å…³é”®æ–¹æ³•æ£€æŸ¥
    key_methods = [
        ('getDeviceId', 'è·å–è®¾å¤‡ID'),
        ('getSubscriberId', 'è·å–è®¢é˜…è€…ID'),
        ('getSimSerialNumber', 'è·å–SIMåºåˆ—å·'),
        ('sendTextMessage', 'å‘é€çŸ­ä¿¡'),
        ('Log', 'æ—¥å¿—è¾“å‡º'),
        ('<init>', 'æ„é€ å‡½æ•°'),
        ('getIntent', 'è·å–Intent'),
        ('putExtra', 'æ·»åŠ Extra'),
        ('startService', 'å¯åŠ¨æœåŠ¡'),
        ('sendBroadcast', 'å‘é€å¹¿æ’­'),
    ]

    issues.append("\nğŸ” å…³é”®æ–¹æ³•æ£€æŸ¥:")
    for method, desc in key_methods:
        found = [e for e in all_entries if method in e]
        if found:
            issues.append(f"  âœ“ {desc} ({method}): {len(found)} ä¸ª")
        else:
            issues.append(f"  âœ— {desc} ({method}): æœªæ‰¾åˆ°")

    # ç±»å‹æ£€æŸ¥
    issues.append("\nğŸ“Š ç±»å‹ç»Ÿè®¡:")
    type_counts = defaultdict(int)
    for entry in all_entries:
        # æå–æ‰€æœ‰ java.xxx å’Œ android.xxx ç±»å‹
        types = re.findall(r'(?:java|android|javax)\.[a-zA-Z0-9.]+', entry)
        for t in types:
            type_counts[t] += 1

    # æ˜¾ç¤ºæœ€å¸¸è§çš„ç±»å‹
    common_types = sorted(type_counts.items(), key=lambda x: -x[1])[:10]
    for type_name, count in common_types:
        issues.append(f"  - {type_name}: {count} æ¬¡")

    return issues


def main():
    print("=" * 80)
    print("LDFA SourcesAndSinks å…¨é¢æ£€æŸ¥")
    print("=" * 80)

    file_path = Path('/Users/zhangyiming/My_Documents/My_Code/LDFA-dataset/TaintBench/LDFA_SourcesAndSinks.txt')

    if not file_path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return

    # åŠ è½½æ¡ç›®
    sources, sinks = load_entries(file_path)

    print(f"\nğŸ“‹ åŸºæœ¬ä¿¡æ¯:")
    print(f"  Sources: {len(sources)}")
    print(f"  Sinks: {len(sinks)}")
    print(f"  æ€»è®¡: {len(sources) + len(sinks)}")

    # æ£€æŸ¥1: æ ¼å¼ä¸€è‡´æ€§
    print(f"\n{'=' * 80}")
    print("æ£€æŸ¥ 1: æ ¼å¼ä¸€è‡´æ€§")
    print("=" * 80)
    issues = check_format_consistency(sources, sinks)
    for issue in issues:
        print(issue)

    # æ£€æŸ¥2: ä¸åŸå§‹æ–‡ä»¶å¯¹æ¯”
    print(f"\n{'=' * 80}")
    print("æ£€æŸ¥ 2: ä¸åŸå§‹æ–‡ä»¶å¯¹æ¯”")
    print("=" * 80)
    issues = compare_with_sources(sources, sinks)
    for issue in issues:
        print(issue)

    # æ£€æŸ¥3: ç‰¹å®šæ¨¡å¼å’Œå…³é”®æ–¹æ³•
    print(f"\n{'=' * 80}")
    print("æ£€æŸ¥ 3: å…³é”®æ–¹æ³•å’Œç±»å‹ç»Ÿè®¡")
    print("=" * 80)
    issues = check_specific_patterns(sources, sinks)
    for issue in issues:
        print(issue)

    # æ£€æŸ¥4: å‚æ•°æ ¼å¼æ ‡å‡†åŒ–é—®é¢˜
    print(f"\n{'=' * 80}")
    print("æ£€æŸ¥ 4: å‚æ•°æ ¼å¼æ ‡å‡†åŒ–å»ºè®®")
    print("=" * 80)

    all_entries = sources | sinks
    param_format_issues = []

    for entry in list(all_entries)[:50]:  # æ£€æŸ¥å‰50ä¸ª
        match = re.search(r'\(([^)]+)\)', entry)
        if match:
            params = match.group(1)
            # æ£€æŸ¥å‚æ•°ä¹‹é—´çš„ç©ºæ ¼æ˜¯å¦ä¸€è‡´
            if ', ' in params and ',' in params.replace(', ', ''):
                param_format_issues.append(f"å‚æ•°ç©ºæ ¼ä¸ä¸€è‡´: {entry[:100]}")

    if param_format_issues:
        print(f"å‘ç° {len(param_format_issues)} ä¸ªå‚æ•°æ ¼å¼ä¸ä¸€è‡´çš„æ¡ç›®ï¼ˆå‰50ä¸ªä¸­ï¼‰:")
        for issue in param_format_issues[:5]:
            print(f"  - {issue}")
    else:
        print("âœ“ å‚æ•°æ ¼å¼ä¸€è‡´æ€§è‰¯å¥½")

    print(f"\n{'=' * 80}")
    print("æ£€æŸ¥å®Œæˆ")
    print("=" * 80)


if __name__ == '__main__':
    main()
